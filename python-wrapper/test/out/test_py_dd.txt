Network with 2 layers
    Dense(dyn): 784 -> RELU -> 16
    Dense(dyn): 16 -> SOFTMAX -> 10
Total parameters: 12730

 ------------------------------------------------------------
 | Index | Layer                | Parameters | Output Shape |
 ------------------------------------------------------------
 | 0     | Dense(RELU) (dyn)    |      12560 | [Bx16]       |
 | 1     | Dense(SOFTMAX) (dyn) |        170 | [Bx10]       |
 ------------------------------------------------------------
                Total Parameters:      12730
Network with 2 layers
    Dense(dyn): 784 -> RELU -> 16
    Dense(dyn): 16 -> SOFTMAX -> 10
Total parameters: 12730

 ------------------------------------------------------------
 | Index | Layer                | Parameters | Output Shape |
 ------------------------------------------------------------
 | 0     | Dense(RELU) (dyn)    |      12560 | [Bx16]       |
 | 1     | Dense(SOFTMAX) (dyn) |        170 | [Bx10]       |
 ------------------------------------------------------------
                Total Parameters:      12730

Train the network with "Stochastic Gradient Descent"
    Updater: MOMENTUM
       Loss: CATEGORICAL_CROSS_ENTROPY
 Early Stop: Goal(error)

With parameters:
          epochs=5
      batch_size=100
   learning_rate=0.1
        momentum=0.85

epoch   0/5 batch    1/ 600 - error: 0.89000 loss: 2.34403 ETA 0s
epoch   0/5 batch  600/ 600 - error: 0.06792 loss: 0.22741 time 233ms 
epoch   1/5 batch    1/ 600 - error: 0.06000 loss: 0.17531 ETA 0s
epoch   1/5 batch  600/ 600 - error: 0.05467 loss: 0.18826 time 245ms 
epoch   2/5 batch    1/ 600 - error: 0.06000 loss: 0.23079 ETA 0s
epoch   2/5 batch  600/ 600 - error: 0.05372 loss: 0.18121 time 229ms 
epoch   3/5 batch    1/ 600 - error: 0.04000 loss: 0.13964 ETA 0s
epoch   3/5 batch  600/ 600 - error: 0.05065 loss: 0.16800 time 235ms 
epoch   4/5 batch    1/ 600 - error: 0.03000 loss: 0.10470 ETA 0s
epoch   4/5 batch  600/ 600 - error: 0.05475 loss: 0.18009 time 228ms 
Restore the best (error) weights from epoch 3
Training took 1s

Evaluation Results
   error: 0.05830 
    loss: 0.20129 
evaluation took 7ms 
